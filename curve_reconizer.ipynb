{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a898cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "#import cv2\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "from mrcnn.visualize import display_instances\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790e99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTES\n",
    "# Root directory of the project\n",
    "BASE_DIR = \"C:\\\\Users\\\\hp\\\\Desktop\\\\Data Science\\\\Projet Alain\\\\Curve_Reconizer\"\n",
    "DEFAULT_LOGS_DIR = os.path.join(BASE_DIR, \"logs\")\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"logs\")\n",
    "WEIGHTS_PATH = \"C:\\\\Users\\\\hp\\\\Desktop\\\\Data Science\\\\Projet Alain\\\\Curve_Reconizer\\\\logs\\\\object20210629T2054\\\\mask_rcnn_object_0020.h5\"   # change it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConfig(Config):\n",
    "    '''Configuration pour entrainer notre dataset customisé'''\n",
    "\n",
    "    NAME = \"object\"\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 2  # Nombre de classes = Background + success et failure\n",
    "    STEPS_PER_EPOCH = 10 # Nombre d'étapes d'apprentissage par epoch\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9 # Sauter les détections avec un niveau de confiance < 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(utils.Dataset):\n",
    "    \n",
    "    def load_custom(self, dataset_dir, subset):\n",
    "\n",
    "        self.add_class(\"object\", 1, \"success\")\n",
    "        self.add_class(\"object\", 2, \"failure\")\n",
    "\n",
    "        # Train Dataset or Validation Dataset\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        annotations1 = json.load(open('C:\\\\Users\\\\hp\\\\Desktop\\\\Data Science\\\\Projet Alain\\\\Curve_Reconizer\\\\datasets\\\\train\\\\train_annoted.json'))\n",
    "        annotations = list(annotations1.values())\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "        \n",
    "        # Add images\n",
    "        for a in annotations:\n",
    "            # Obtention des coordonnées x, y des points des polygones qui composent le contour de chaque instance d'objet.\n",
    "            polygons = [r['shape_attributes'] for r in a['regions']] \n",
    "            objects = [s['region_attributes']['names'] for s in a['regions']]\n",
    "            print(\"objects:\",objects)\n",
    "            name_dict = {\"success\": 1,\"failure\": 2}\n",
    "\n",
    "            num_ids = [name_dict[a] for a in objects]\n",
    "            print(\"numids\",num_ids)\n",
    "\n",
    "            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            self.add_image(\n",
    "                \"object\",  ## for a single class just add the name here\n",
    "                image_id=a['filename'],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons,\n",
    "                num_ids=num_ids\n",
    "                )\n",
    "            \n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Générer des masques d'instance pour une image.\n",
    "       Returns:\n",
    "        masks:  Un tableau bool de forme [hauteur, largeur, nombre d'instances] avec un masque par instance.\n",
    "        class_ids: un tableau 1D d'ID de classe des masques d'instance.\n",
    "        \"\"\"\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"object\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convertir les polygones en un masque bitmap de forme\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] != \"object\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "        \n",
    "        num_ids = info['num_ids']\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])], dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "        \trr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1.\n",
    "        num_ids = np.array(num_ids, dtype=np.int32)\n",
    "        return mask, num_ids #np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Retourne le chemin de l'image\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"object\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b87dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Model\n",
    "TEST_MODE = \"inference\"\n",
    "BASE_DIR = \"C:\\\\Users\\\\hp\\\\Desktop\\\\Data Science\\\\Projet Alain\\\\Curve_Reconizer\\\\datasets\"\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"\n",
    "      Retourne un tableau d'axes Matplotlib à utiliser dans toutes les visualisations du carnet.  \n",
    "      Fournit un point central pour contrôler la taille des graphiques. \n",
    "      Ajustez l'attribut size pour contrôler la taille des images à rendre.\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "\n",
    "\n",
    "# Chargement du validation set\n",
    "dataset = CustomDataset()\n",
    "dataset.load_custom(BASE_DIR, \"val\")\n",
    "dataset.prepare()\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683fd652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle en mode inférence\n",
    "config = CustomConfig()\n",
    "model = modellib.MaskRCNN(mode='inference', model_dir=MODEL_DIR, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25621f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des poids \n",
    "print('Chargement des poids...')\n",
    "weights_path = WEIGHTS_PATH\n",
    "model.load(weightd_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd47ccc",
   "metadata": {},
   "source": [
    "### Test avec une image non présente dans la BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944aeabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = 'Chemin de la nouvelle image'\n",
    "image1 = mpimg.imread(new_image)\n",
    "results = model.detect([image1], verbose=1)\n",
    "\n",
    "# Affichage du résultat\n",
    "ax = get_ax(1)\n",
    "r1 = results[0]\n",
    "visualize.display_instances(image1, r1['rois'], r1['masks'], r1['class_ids'],\n",
    "dataset.class_names, r1['scores'], ax=ax, title=\"Predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
